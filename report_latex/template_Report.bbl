\begin{thebibliography}{80}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Artetxe and Schwenk(2018)]{artetxe2018massively}
M.~Artetxe and H.~Schwenk.
\newblock Massively multilingual sentence embeddings for zero-shot
  cross-lingual transfer and beyond.
\newblock \emph{arXiv preprint arXiv:1812.10464}, 2018.

\bibitem[Axelrod et~al.(2011)Axelrod, He, and Gao]{axelrod2011domain}
A.~Axelrod, X.~He, and J.~Gao.
\newblock Domain adaptation via pseudo in-domain data selection.
\newblock In \emph{Proceedings of the conference on empirical methods in
  natural language processing}, pages 355--362. Association for Computational
  Linguistics, 2011.

\bibitem[Baxter(2000)]{baxter2000model}
J.~Baxter.
\newblock A model of inductive bias learning.
\newblock \emph{Journal of Artificial Intelligence Research}, 12:\penalty0
  149--198, 2000.

\bibitem[Bengio et~al.(2003)Bengio, Ducharme, Vincent, and
  Jauvin]{bengio2003neural}
Y.~Bengio, R.~Ducharme, P.~Vincent, and C.~Jauvin.
\newblock A neural probabilistic language model.
\newblock \emph{Journal of machine learning research}, 3\penalty0
  (Feb):\penalty0 1137--1155, 2003.

\bibitem[Bickel et~al.(2009)Bickel, Br{\"u}ckner, and
  Scheffer]{bickel2009discriminative}
S.~Bickel, M.~Br{\"u}ckner, and T.~Scheffer.
\newblock Discriminative learning under covariate shift.
\newblock \emph{Journal of Machine Learning Research}, 10\penalty0
  (Sep):\penalty0 2137--2155, 2009.

\bibitem[Blei et~al.(2003)Blei, Ng, and Jordan]{blei2003latent}
D.~M. Blei, A.~Y. Ng, and M.~I. Jordan.
\newblock Latent dirichlet allocation.
\newblock \emph{Journal of machine Learning research}, 3\penalty0
  (Jan):\penalty0 993--1022, 2003.

\bibitem[Blitzer et~al.(2006)Blitzer, McDonald, and Pereira]{blitzer2006domain}
J.~Blitzer, R.~McDonald, and F.~Pereira.
\newblock Domain adaptation with structural correspondence learning.
\newblock In \emph{Proceedings of the 2006 conference on empirical methods in
  natural language processing}, pages 120--128. Association for Computational
  Linguistics, 2006.

\bibitem[Blitzer et~al.(2007)Blitzer, Dredze, and
  Pereira]{blitzer2007biographies}
J.~Blitzer, M.~Dredze, and F.~Pereira.
\newblock Biographies, bollywood, boom-boxes and blenders: Domain adaptation
  for sentiment classification.
\newblock In \emph{Proceedings of the 45th annual meeting of the association of
  computational linguistics}, pages 440--447, 2007.

\bibitem[Blum and Mitchell(1998)]{blum1998combining}
A.~Blum and T.~Mitchell.
\newblock Combining labeled and unlabeled data with co-training.
\newblock In \emph{Proceedings of the eleventh annual conference on
  Computational learning theory}, pages 92--100. ACM, 1998.

\bibitem[Bojanowski et~al.(2017)Bojanowski, Grave, Joulin, and
  Mikolov]{bojanowski2017enriching}
P.~Bojanowski, E.~Grave, A.~Joulin, and T.~Mikolov.
\newblock Enriching word vectors with subword information.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  5:\penalty0 135--146, 2017.

\bibitem[Bollegala et~al.(2015)Bollegala, Maehara, and
  Kawarabayashi]{bollegala2015unsupervised}
D.~Bollegala, T.~Maehara, and K.-i. Kawarabayashi.
\newblock Unsupervised cross-domain word representation learning.
\newblock \emph{arXiv preprint arXiv:1505.07184}, 2015.

\bibitem[Caruna(1993)]{caruna1993multitask}
R.~Caruna.
\newblock Multitask learning: A knowledge-based source of inductive bias.
\newblock In \emph{Machine Learning: Proceedings of the Tenth International
  Conference}, pages 41--48, 1993.

\bibitem[Chan and Ng(2006)]{chan2006estimating}
Y.~S. Chan and H.~T. Ng.
\newblock Estimating class priors in domain adaptation for word sense
  disambiguation.
\newblock In \emph{Proceedings of the 21st International Conference on
  Computational Linguistics and the 44th annual meeting of the Association for
  Computational Linguistics}, pages 89--96. Association for Computational
  Linguistics, 2006.

\bibitem[Changpinyo et~al.(2018)Changpinyo, Hu, and Sha]{changpinyo2018multi}
S.~Changpinyo, H.~Hu, and F.~Sha.
\newblock Multi-task learning for sequence tagging: An empirical study.
\newblock \emph{arXiv preprint arXiv:1808.04151}, 2018.

\bibitem[Chelba and Acero(2006)]{chelba2006adaptation}
C.~Chelba and A.~Acero.
\newblock Adaptation of maximum entropy capitalizer: Little data can help a
  lot.
\newblock \emph{Computer Speech \& Language}, 20\penalty0 (4):\penalty0
  382--399, 2006.

\bibitem[Chen et~al.(2012)Chen, Xu, Weinberger, and Sha]{chen2012marginalized}
M.~Chen, Z.~Xu, K.~Weinberger, and F.~Sha.
\newblock Marginalized denoising autoencoders for domain adaptation.
\newblock \emph{arXiv preprint arXiv:1206.4683}, 2012.

\bibitem[Chu et~al.(2017)Chu, Dabre, and Kurohashi]{chu2017empirical}
C.~Chu, R.~Dabre, and S.~Kurohashi.
\newblock An empirical comparison of simple domain adaptation methods for
  neural machine translation.
\newblock \emph{arXiv preprint arXiv:1701.03214}, 2017.

\bibitem[Clark et~al.(2018)Clark, Luong, Manning, and Le]{clark2018semi}
K.~Clark, M.-T. Luong, C.~D. Manning, and Q.~V. Le.
\newblock Semi-supervised sequence modeling with cross-view training.
\newblock \emph{arXiv preprint arXiv:1809.08370}, 2018.

\bibitem[Collobert and Weston(2008)]{collobert2008unified}
R.~Collobert and J.~Weston.
\newblock A unified architecture for natural language processing: Deep neural
  networks with multitask learning.
\newblock In \emph{Proceedings of the 25th international conference on Machine
  learning}, pages 160--167. ACM, 2008.

\bibitem[Conneau et~al.(2017)Conneau, Lample, Ranzato, Denoyer, and
  J{\'e}gou]{conneau2017word}
A.~Conneau, G.~Lample, M.~Ranzato, L.~Denoyer, and H.~J{\'e}gou.
\newblock Word translation without parallel data.
\newblock \emph{arXiv preprint arXiv:1710.04087}, 2017.

\bibitem[Daume~III(2007)]{daume2007frustratingly}
H.~Daume~III.
\newblock Frustratingly easy domain adaptation.
\newblock In \emph{Proceedings of the 45th Annual Meeting of the Association of
  Computational Linguistics}, pages 256--263, 2007.

\bibitem[Daum{\'e}~III et~al.(2010)Daum{\'e}~III, Kumar, and
  Saha]{daume2010frustratingly}
H.~Daum{\'e}~III, A.~Kumar, and A.~Saha.
\newblock Frustratingly easy semi-supervised domain adaptation.
\newblock In \emph{Proceedings of the 2010 Workshop on Domain Adaptation for
  Natural Language Processing}, pages 53--59. Association for Computational
  Linguistics, 2010.

\bibitem[Deerwester et~al.(1990)Deerwester, Dumais, Furnas, Landauer, and
  Harshman]{deerwester1990indexing}
S.~Deerwester, S.~T. Dumais, G.~W. Furnas, T.~K. Landauer, and R.~Harshman.
\newblock Indexing by latent semantic analysis.
\newblock \emph{Journal of the American society for information science},
  41\penalty0 (6):\penalty0 391--407, 1990.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{Computer Vision and Pattern Recognition, 2009. CVPR 2009.
  IEEE Conference on}, pages 248--255. Ieee, 2009.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Finkel and Manning(2009)]{finkel2009hierarchical}
J.~R. Finkel and C.~D. Manning.
\newblock Hierarchical bayesian domain adaptation.
\newblock In \emph{Proceedings of Human Language Technologies: The 2009 Annual
  Conference of the North American Chapter of the Association for Computational
  Linguistics}, pages 602--610. Association for Computational Linguistics,
  2009.

\bibitem[Ganin et~al.(2016)Ganin, Ustinova, Ajakan, Germain, Larochelle,
  Laviolette, Marchand, and Lempitsky]{ganin2016domain}
Y.~Ganin, E.~Ustinova, H.~Ajakan, P.~Germain, H.~Larochelle, F.~Laviolette,
  M.~Marchand, and V.~Lempitsky.
\newblock Domain-adversarial training of neural networks.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 2096--2030, 2016.

\bibitem[Glorot et~al.(2011)Glorot, Bordes, and Bengio]{glorot2011domain}
X.~Glorot, A.~Bordes, and Y.~Bengio.
\newblock Domain adaptation for large-scale sentiment classification: A deep
  learning approach.
\newblock In \emph{Proceedings of the 28th international conference on machine
  learning (ICML-11)}, pages 513--520, 2011.

\bibitem[Goldberg(2017)]{goldberg2017neural}
Y.~Goldberg.
\newblock Neural network methods for natural language processing.
\newblock \emph{Synthesis Lectures on Human Language Technologies}, 10\penalty0
  (1):\penalty0 1--309, 2017.

\bibitem[Guo et~al.(2009)Guo, Zhu, Guo, Zhang, Wu, and Su]{guo2009domain}
H.~Guo, H.~Zhu, Z.~Guo, X.~Zhang, X.~Wu, and Z.~Su.
\newblock Domain adaptation with latent semantic association for named entity
  recognition.
\newblock In \emph{Proceedings of Human Language Technologies: The 2009 Annual
  Conference of the North American Chapter of the Association for Computational
  Linguistics}, pages 281--289. Association for Computational Linguistics,
  2009.

\bibitem[Hashimoto et~al.(2016)Hashimoto, Xiong, Tsuruoka, and
  Socher]{hashimoto2016joint}
K.~Hashimoto, C.~Xiong, Y.~Tsuruoka, and R.~Socher.
\newblock A joint many-task model: Growing a neural network for multiple nlp
  tasks.
\newblock \emph{arXiv preprint arXiv:1611.01587}, 2016.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem[Himmetoglu(2016)]{DSC:2016}
B.~Himmetoglu.
\newblock Deciphering the neural language model.
\newblock
  \url{https://burakhimmetoglu.com/2016/12/16/deciphering-the-neural-language-model/},
  2016.

\bibitem[Hofmann(1999)]{hofmann1999probabilistic}
T.~Hofmann.
\newblock Probabilistic latent semantic analysis.
\newblock In \emph{Proceedings of the Fifteenth conference on Uncertainty in
  artificial intelligence}, pages 289--296. Morgan Kaufmann Publishers Inc.,
  1999.

\bibitem[Howard and Ruder(2018)]{howard2018universal}
J.~Howard and S.~Ruder.
\newblock Universal language model fine-tuning for text classification.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, volume~1, pages
  328--339, 2018.

\bibitem[Huh et~al.(2016)Huh, Agrawal, and Efros]{huh2016makes}
M.~Huh, P.~Agrawal, and A.~A. Efros.
\newblock What makes imagenet good for transfer learning?
\newblock \emph{arXiv preprint arXiv:1608.08614}, 2016.

\bibitem[Jiang(2008)]{jiang2008literature}
J.~Jiang.
\newblock A literature survey on domain adaptation of statistical classifiers.
\newblock \emph{URL: http://sifaka. cs. uiuc.
  edu/jiang4/domainadaptation/survey}, 3:\penalty0 1--12, 2008.

\bibitem[Jiang and Zhai(2007)]{jiang2007instance}
J.~Jiang and C.~Zhai.
\newblock Instance weighting for domain adaptation in nlp.
\newblock In \emph{Proceedings of the 45th annual meeting of the association of
  computational linguistics}, pages 264--271, 2007.

\bibitem[Johnson et~al.(2017)Johnson, Schuster, Le, Krikun, Wu, Chen, Thorat,
  Vi{\'e}gas, Wattenberg, Corrado, et~al.]{johnson2017google}
M.~Johnson, M.~Schuster, Q.~V. Le, M.~Krikun, Y.~Wu, Z.~Chen, N.~Thorat,
  F.~Vi{\'e}gas, M.~Wattenberg, G.~Corrado, et~al.
\newblock Googleâ€™s multilingual neural machine translation system: Enabling
  zero-shot translation.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  5:\penalty0 339--351, 2017.

\bibitem[Lee et~al.(2017)Lee, Dernoncourt, and Szolovits]{lee2017transfer}
J.~Y. Lee, F.~Dernoncourt, and P.~Szolovits.
\newblock Transfer learning for named-entity recognition with neural networks.
\newblock \emph{arXiv preprint arXiv:1705.06273}, 2017.

\bibitem[Li et~al.(2015)Li, Luong, and Jurafsky]{li2015hierarchical}
J.~Li, M.-T. Luong, and D.~Jurafsky.
\newblock A hierarchical neural autoencoder for paragraphs and documents.
\newblock \emph{arXiv preprint arXiv:1506.01057}, 2015.

\bibitem[Li(2012)]{li2012literature}
Q.~Li.
\newblock Literature survey: domain adaptation algorithms for natural language
  processing.
\newblock \emph{Department of Computer Science The Graduate Center, The City
  University of New York}, pages 8--10, 2012.

\bibitem[Liu et~al.(2015)Liu, Gao, He, Deng, Duh, and
  Wang]{liu2015representation}
X.~Liu, J.~Gao, X.~He, L.~Deng, K.~Duh, and Y.-Y. Wang.
\newblock Representation learning using multi-task deep neural networks for
  semantic classification and information retrieval.
\newblock 2015.

\bibitem[Mallapragada et~al.(2009)Mallapragada, Jin, Jain, and
  Liu]{mallapragada2009semiboost}
P.~K. Mallapragada, R.~Jin, A.~K. Jain, and Y.~Liu.
\newblock Semiboost: Boosting for semi-supervised learning.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 31\penalty0 (11):\penalty0 2000--2014, 2009.

\bibitem[Marcus et~al.(1993)Marcus, Marcinkiewicz, and
  Santorini]{marcus1993building}
M.~P. Marcus, M.~A. Marcinkiewicz, and B.~Santorini.
\newblock Building a large annotated corpus of english: The penn treebank.
\newblock \emph{Computational linguistics}, 19\penalty0 (2):\penalty0 313--330,
  1993.

\bibitem[Mikolov et~al.(2013)Mikolov, Sutskever, Chen, Corrado, and
  Dean]{mikolov2013distributed}
T.~Mikolov, I.~Sutskever, K.~Chen, G.~S. Corrado, and J.~Dean.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In \emph{Advances in neural information processing systems}, pages
  3111--3119, 2013.

\bibitem[Mou et~al.(2016)Mou, Meng, Yan, Li, Xu, Zhang, and
  Jin]{mou2016transferable}
L.~Mou, Z.~Meng, R.~Yan, G.~Li, Y.~Xu, L.~Zhang, and Z.~Jin.
\newblock How transferable are neural networks in nlp applications?
\newblock \emph{arXiv preprint arXiv:1603.06111}, 2016.

\bibitem[Pan et~al.(2010)Pan, Yang, et~al.]{pan2010survey}
S.~J. Pan, Q.~Yang, et~al.
\newblock A survey on transfer learning.
\newblock \emph{IEEE Transactions on knowledge and data engineering},
  22\penalty0 (10):\penalty0 1345--1359, 2010.

\bibitem[Pennington et~al.(2014)Pennington, Socher, and
  Manning]{pennington2014glove}
J.~Pennington, R.~Socher, and C.~Manning.
\newblock Glove: Global vectors for word representation.
\newblock In \emph{Proceedings of the 2014 conference on empirical methods in
  natural language processing (EMNLP)}, pages 1532--1543, 2014.

\bibitem[Peters et~al.(2018)Peters, Neumann, Iyyer, Gardner, Clark, Lee, and
  Zettlemoyer]{peters2018deep}
M.~E. Peters, M.~Neumann, M.~Iyyer, M.~Gardner, C.~Clark, K.~Lee, and
  L.~Zettlemoyer.
\newblock Deep contextualized word representations.
\newblock \emph{arXiv preprint arXiv:1802.05365}, 2018.

\bibitem[Petrov and McDonald(2012)]{petrov2012overview}
S.~Petrov and R.~McDonald.
\newblock Overview of the 2012 shared task on parsing the web.
\newblock In \emph{Notes of the first workshop on syntactic analysis of
  non-canonical language (sancl)}, volume~59. Citeseer, 2012.

\bibitem[Pinto et~al.(2009)Pinto, Civera, Barr{\'o}n-Cedeno, Juan, and
  Rosso]{pinto2009statistical}
D.~Pinto, J.~Civera, A.~Barr{\'o}n-Cedeno, A.~Juan, and P.~Rosso.
\newblock A statistical approach to crosslingual natural language tasks.
\newblock \emph{Journal of Algorithms}, 64\penalty0 (1):\penalty0 51--60, 2009.

\bibitem[Plank(2016)]{plank2016non}
B.~Plank.
\newblock What to do about non-standard (or non-canonical) language in nlp.
\newblock \emph{arXiv preprint arXiv:1608.07836}, 2016.

\bibitem[Plank et~al.(2014)Plank, Johannsen, and
  S{\o}gaard]{plank2014importance}
B.~Plank, A.~Johannsen, and A.~S{\o}gaard.
\newblock Importance weighting and unsupervised domain adaptation of pos
  taggers: a negative result.
\newblock In \emph{Proceedings of the 2014 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 968--973, 2014.

\bibitem[Plank et~al.(2016)Plank, S{\o}gaard, and
  Goldberg]{plank2016multilingual}
B.~Plank, A.~S{\o}gaard, and Y.~Goldberg.
\newblock Multilingual part-of-speech tagging with bidirectional long
  short-term memory models and auxiliary loss.
\newblock \emph{arXiv preprint arXiv:1604.05529}, 2016.

\bibitem[Rei(2017)]{rei2017semi}
M.~Rei.
\newblock Semi-supervised multitask learning for sequence labeling.
\newblock \emph{arXiv preprint arXiv:1704.07156}, 2017.

\bibitem[Ruder(2018)]{NLPImage:2018}
S.~Ruder.
\newblock Nlp's imagenet moment has arrived.
\newblock \url{https://thegradient.pub/nlp-imagenet/}, 2018.

\bibitem[Ruder and Plank(2017)]{ruder2017learning}
S.~Ruder and B.~Plank.
\newblock Learning to select data for transfer learning with bayesian
  optimization.
\newblock \emph{arXiv preprint arXiv:1707.05246}, 2017.

\bibitem[Ruder and Plank(2018)]{ruder2018strong}
S.~Ruder and B.~Plank.
\newblock Strong baselines for neural semi-supervised learning under domain
  shift.
\newblock \emph{arXiv preprint arXiv:1804.09530}, 2018.

\bibitem[Santos and Zadrozny(2014)]{santos2014learning}
C.~D. Santos and B.~Zadrozny.
\newblock Learning character-level representations for part-of-speech tagging.
\newblock In \emph{Proceedings of the 31st International Conference on Machine
  Learning (ICML-14)}, pages 1818--1826, 2014.

\bibitem[Schnabel and Sch{\"u}tze(2014)]{schnabel2014flors}
T.~Schnabel and H.~Sch{\"u}tze.
\newblock Flors: Fast and simple domain adaptation for part-of-speech tagging.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  2:\penalty0 15--26, 2014.

\bibitem[Sharif~Razavian et~al.(2014)Sharif~Razavian, Azizpour, Sullivan, and
  Carlsson]{sharif2014cnn}
A.~Sharif~Razavian, H.~Azizpour, J.~Sullivan, and S.~Carlsson.
\newblock Cnn features off-the-shelf: an astounding baseline for recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition workshops}, pages 806--813, 2014.

\bibitem[S{\o}gaard and Goldberg(2016)]{sogaard2016deep}
A.~S{\o}gaard and Y.~Goldberg.
\newblock Deep multi-task learning with low level tasks supervised at lower
  layers.
\newblock In \emph{Proceedings of the 54th Annual Meeting of the Association
  for Computational Linguistics (Volume 2: Short Papers)}, volume~2, pages
  231--235, 2016.

\bibitem[Srivastava et~al.(2018)Srivastava, Labutov, and
  Mitchell]{srivastava2018zero}
S.~Srivastava, I.~Labutov, and T.~Mitchell.
\newblock Zero-shot learning of classifiers from natural language
  quantification.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, volume~1, pages
  306--316, 2018.

\bibitem[Torrey and Shavlik(2010)]{torrey2010transfer}
L.~Torrey and J.~Shavlik.
\newblock Transfer learning.
\newblock In \emph{Handbook of Research on Machine Learning Applications and
  Trends: Algorithms, Methods, and Techniques}, pages 242--264. IGI Global,
  2010.

\bibitem[Toutanova and Manning(2000)]{toutanova2000enriching}
K.~Toutanova and C.~D. Manning.
\newblock Enriching the knowledge sources used in a maximum entropy
  part-of-speech tagger.
\newblock In \emph{Proceedings of the 2000 Joint SIGDAT conference on Empirical
  methods in natural language processing and very large corpora: held in
  conjunction with the 38th Annual Meeting of the Association for Computational
  Linguistics-Volume 13}, pages 63--70. Association for Computational
  Linguistics, 2000.

\bibitem[Trask et~al.(2015)Trask, Michalak, and Liu]{trask2015sense2vec}
A.~Trask, P.~Michalak, and J.~Liu.
\newblock sense2vec-a fast and accurate method for word sense disambiguation in
  neural word embeddings.
\newblock \emph{arXiv preprint arXiv:1511.06388}, 2015.

\bibitem[Upadhyay et~al.(2018)Upadhyay, Faruqui, T{\"u}r, Dilek, and
  Heck]{upadhyay2018almost}
S.~Upadhyay, M.~Faruqui, G.~T{\"u}r, H.-T. Dilek, and L.~Heck.
\newblock (almost) zero-shot cross-lingual spoken language understanding.
\newblock In \emph{2018 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pages 6034--6038. IEEE, 2018.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  {\L}.~Kaiser, and I.~Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  5998--6008, 2017.

\bibitem[Vincent et~al.(2008)Vincent, Larochelle, Bengio, and
  Manzagol]{vincent2008extracting}
P.~Vincent, H.~Larochelle, Y.~Bengio, and P.-A. Manzagol.
\newblock Extracting and composing robust features with denoising autoencoders.
\newblock In \emph{Proceedings of the 25th international conference on Machine
  learning}, pages 1096--1103. ACM, 2008.

\bibitem[Vinyals et~al.(2016)Vinyals, Blundell, Lillicrap, Wierstra,
  et~al.]{vinyals2016matching}
O.~Vinyals, C.~Blundell, T.~Lillicrap, D.~Wierstra, et~al.
\newblock Matching networks for one shot learning.
\newblock In \emph{Advances in neural information processing systems}, pages
  3630--3638, 2016.

\bibitem[Xia et~al.(2013)Xia, Hu, Lu, Yang, Zong, et~al.]{xia2013instance}
R.~Xia, X.~Hu, J.~Lu, J.~Yang, C.~Zong, et~al.
\newblock Instance selection and instance weighting for cross-domain sentiment
  classification via pu learning.
\newblock In \emph{IJCAI}, pages 2176--2182, 2013.

\bibitem[Xu et~al.(2011)Xu, Xu, and Wang]{xu2011instance}
R.~Xu, J.~Xu, and X.~Wang.
\newblock Instance level transfer learning for cross lingual opinion analysis.
\newblock In \emph{Proceedings of the 2nd Workshop on Computational Approaches
  to Subjectivity and Sentiment Analysis}, pages 182--188. Association for
  Computational Linguistics, 2011.

\bibitem[Yang et~al.(2007)Yang, Yan, and Hauptmann]{yang2007adapting}
J.~Yang, R.~Yan, and A.~G. Hauptmann.
\newblock Adapting svm classifiers to data with shifted distributions.
\newblock In \emph{Data Mining Workshops, 2007. ICDM Workshops 2007. Seventh
  IEEE International Conference on}, pages 69--76. IEEE, 2007.

\bibitem[Yang et~al.(2017)Yang, Lu, and Zheng]{yang2017simple}
W.~Yang, W.~Lu, and V.~Zheng.
\newblock A simple regularization-based algorithm for learning cross-domain
  word embeddings.
\newblock In \emph{Proceedings of the 2017 Conference on Empirical Methods in
  Natural Language Processing}, pages 2898--2904, 2017.

\bibitem[Yang and Eisenstein(2015)]{yang2015unsupervised}
Y.~Yang and J.~Eisenstein.
\newblock Unsupervised multi-domain adaptation with feature embeddings.
\newblock In \emph{Proceedings of the 2015 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 672--682, 2015.

\bibitem[Yarowsky(1995)]{yarowsky1995unsupervised}
D.~Yarowsky.
\newblock Unsupervised word sense disambiguation rivaling supervised methods.
\newblock In \emph{Proceedings of the 33rd annual meeting on Association for
  Computational Linguistics}, pages 189--196. Association for Computational
  Linguistics, 1995.

\bibitem[Yosinski et~al.(2014)Yosinski, Clune, Bengio, and
  Lipson]{yosinski2014transferable}
J.~Yosinski, J.~Clune, Y.~Bengio, and H.~Lipson.
\newblock How transferable are features in deep neural networks?
\newblock In \emph{Advances in neural information processing systems}, pages
  3320--3328, 2014.

\bibitem[Yu and Jiang(2016)]{yu2016learning}
J.~Yu and J.~Jiang.
\newblock Learning sentence embeddings with auxiliary tasks for cross-domain
  sentiment classification.
\newblock In \emph{Proceedings of the 2016 Conference on Empirical Methods in
  Natural Language Processing}, pages 236--246, 2016.

\bibitem[Ziser and Reichart(2018)]{ziser2018pivot}
Y.~Ziser and R.~Reichart.
\newblock Pivot based language modeling for improved neural domain adaptation.
\newblock In \emph{Proceedings of the 2018 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long Papers)}, volume~1, pages 1241--1251, 2018.

\end{thebibliography}
